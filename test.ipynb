{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'eng-feed'...\n",
      "remote: Enumerating objects: 864, done.\u001b[K\n",
      "remote: Counting objects: 100% (137/137), done.\u001b[K\n",
      "remote: Compressing objects: 100% (80/80), done.\u001b[K\n",
      "remote: Total 864 (delta 52), reused 103 (delta 41), pack-reused 727\u001b[K\n",
      "Receiving objects: 100% (864/864), 1.60 MiB | 7.28 MiB/s, done.\n",
      "Resolving deltas: 100% (455/455), done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!git clone https://github.com/haffi96/eng-feed # replace any repository of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.ollama import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"mistral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import glob\n",
    "\n",
    "path = pathlib.Path.home() / \"code\" / \"eng-feed\"\n",
    "\n",
    "all_files = []\n",
    "\n",
    "ts_files = all_files.extend(glob.glob(\"./eng-feed\" + '/**/*.ts', recursive=True))\n",
    "astro_files = all_files.extend(glob.glob(\"./eng-feed\" + '/**/*.astro', recursive=True))\n",
    "md_files = all_files.extend(glob.glob(\"./eng-feed\" + '/**/*.md', recursive=True))\n",
    "json_files = all_files.extend(glob.glob(\"./eng-feed\" + '/**/*.json', recursive=True))\n",
    "js_files = all_files.extend(glob.glob(\"./eng-feed\" + '/**/*.js', recursive=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# root_dir = \"./eng-feed/src\"\n",
    "docs = []\n",
    "for file in all_files:\n",
    "    try:\n",
    "        loader = TextLoader(file_path=file, encoding=\"utf-8\")\n",
    "        docs.extend(loader.load_and_split())\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from langchain.vectorstores import DeepLake\n",
    "\n",
    "deeplake_username = \"haffimazhar96\"\n",
    "\n",
    "db = DeepLake(\n",
    "    dataset_path=f\"hub://{deeplake_username}/test\",\n",
    "    embedding=embeddings,\n",
    ")\n",
    "db.add_documents(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in hub://haffimazhar96/eng-feed already exists, loading from the storage\n"
     ]
    }
   ],
   "source": [
    "db = DeepLake(\n",
    "    dataset_path=f\"hub://{deeplake_username}/test\",\n",
    "    read_only=True,\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()\n",
    "retriever.search_kwargs[\"distance_metric\"] = \"cos\"\n",
    "retriever.search_kwargs[\"fetch_k\"] = 100\n",
    "retriever.search_kwargs[\"maximal_marginal_relevance\"] = True\n",
    "retriever.search_kwargs[\"k\"] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "model = ChatOllama(model=\"mistral\")\n",
    "qa = ConversationalRetrievalChain.from_llm(model, retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> **Question**: What does this code repo do? \n",
      "\n",
      "**Answer**: \n",
      "This code snippet is a shell script that implements a pre-rebase hook for Git. The script checks whether the branch being rebased (or empty if rebasing the current branch) is already merged to the publish branch (\"next\" in this example), and takes different actions based on that:\n",
      "\n",
      "1. If the topic branch has ever been merged to \"next\", it prevents the rebase from happening by exiting with a non-zero status. This ensures that previously published history is not overwritten.\n",
      "2. If the topic branch has been fully merged to \"master\", it can be safely deleted.\n",
      "3. If the topic branch still exists and needs to be rebased on top of the current branch, the script does the rebase while excluding the \"publish\" branch (which contains already published history).\n",
      "\n",
      "The script also checks whether the repository is in a detached HEAD state or not. If it's not, it skips the pre-rebase hook step, indicating that the repository isn't ready for a rebase yet. \n",
      "\n",
      "-> **Question**: Where is this app hosted? \n",
      "\n",
      "**Answer**: This information about the hostname of the application can be found in the HTTP response headers using tools like curl or Postman. The hostname is typically included in the `Host` header of the response. \n",
      "\n",
      "-> **Question**: How do users get notified when there is a new post? \n",
      "\n",
      "**Answer**: ```sql\n",
      "--\n",
      "-- Name: all_blogs_id_seq; Type: SEQUENCE SET; Schema: public; Owner: postgres\n",
      "--\n",
      "\n",
      "SELECT pg_catalog.setval('\"public\".\"all_blogs_id_seq\"', 26, true);\n",
      "``` \n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"What does this code repo do?\",\n",
    "    \"Where is this app hosted?\",\n",
    "    \"How do users get notified when there is a new post?\",\n",
    "]\n",
    "chat_history = []\n",
    "\n",
    "for question in questions:\n",
    "    result = qa({\"question\": question, \"chat_history\": chat_history})\n",
    "    chat_history.append((question, result[\"answer\"]))\n",
    "    print(f\"-> **Question**: {question} \\n\")\n",
    "    print(f\"**Answer**: {result['answer']} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_question = [\n",
    "    \"\"\n",
    "]\n",
    "\n",
    "for question in new_question:\n",
    "    result = qa({\"question\": question, \"chat_history\": chat_history})\n",
    "    chat_history.append((question, result[\"answer\"]))\n",
    "    print(f\"-> **Question**: {question} \\n\")\n",
    "    print(f\"**Answer**: {result['answer']} \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llm-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
